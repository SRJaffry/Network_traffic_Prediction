{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Prediction of activities for the given CDR\n",
    "I learned this code from the following source link :\n",
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/'''\n",
    "'''However, the following is coded by my own self'''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the time-series data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DS = pd.read_csv('Filtered_Grid_01.txt')\n",
    "\n",
    "# Consider only the column 'Internet_Activity' from dataframe DS\n",
    "dataset = DS['Internet_Activity']\n",
    "\n",
    "# Change pandas series into numpy arrays\n",
    "series = dataset.values\n",
    "series = series.reshape([len(series), 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     9.431191\n",
       "1     9.082516\n",
       "2     8.340410\n",
       "3    10.518264\n",
       "4    10.463748\n",
       "Name: Internet_Activity, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data set into taining, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split such that training set consist of training_p percent data.\n",
    "training_p = 0.4 #(80/10/10 split for Training/Validation/Test)\n",
    "\n",
    "size_train_main = int(np.floor(len(series)*training_p))\n",
    "size_val_main = int((len(series) - size_train_main)/2)\n",
    "size_test_main = int((len(series) - size_train_main)/2)\n",
    "\n",
    "## Split data\n",
    "train_set_main = series[:size_train_main]\n",
    "valid_set_main = series[size_train_main:-size_val_main]\n",
    "test_set_main = series[size_train_main+size_val_main:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset to train a predictio model for time-series data\n",
    "Step 1: y_train, y_val, y_test are the cloned version of x_train, x_val, x_test, respectively, but shifted by one time step.\n",
    "\n",
    "Step 2: X_* is the input feature, y_* is the label.\n",
    "\n",
    "### Details\n",
    "\n",
    "The (x,y) set is rearranged such that for each value of x, the label y represent the next value in the series (hence y is shifted one step ahead of x). \n",
    "\n",
    "Mathemtically,  y(t) = x(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make x and y labels\n",
    "X_train = pd.DataFrame(train_set_main)\n",
    "y_train = X_train.shift(-1)\n",
    "\n",
    "X_val = pd.DataFrame(valid_set_main)\n",
    "y_val = X_val.shift(-1)\n",
    "\n",
    "X_test = pd.DataFrame(test_set_main)\n",
    "y_test = X_test.shift(-1)\n",
    "\n",
    "# Drop the last element of X_* as we will not have any label for it.\n",
    "X_train.drop(X_train.tail(1), inplace = True)\n",
    "X_val.drop(X_test.tail(1), inplace = True)\n",
    "X_test.drop(X_test.tail(1), inplace = True)\n",
    "\n",
    "#Last element of y_* would have NaN, hence drop it.\n",
    "y_train.dropna(inplace = True)\n",
    "y_val.dropna(inplace = True)\n",
    "y_test.dropna(inplace = True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all the data frames to numpy arrays again.\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_val = X_val.values\n",
    "y_val = y_val.values\n",
    "X_test = X_test.values \n",
    "\n",
    "# How many steps do we want to proceed in the time series\n",
    "n_steps = 1 \n",
    "\n",
    "# How many features do we have in the time series\n",
    "n_features = 1\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], n_steps, n_features))\n",
    "X_val = X_val.reshape((X_val.shape[0], n_steps, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_steps, n_features))\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(50, activation = 'relu', input_shape=(n_steps, n_features)))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "model_LSTM.add(Dense(1))\n",
    "model_LSTM.compile(loss='mae', optimizer = 'adam')\n",
    "\n",
    "history_LSTM = model_LSTM.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val), verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_LSTM.history['loss'], \"bx-\", label='training LSTM', color = \"green\")\n",
    "plt.plot(history_LSTM.history['val_loss'], \"bo-\", label='validation LSTM', color = \"black\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.ylim(0,10)\n",
    "plt.grid()\n",
    "plt.xlabel('Training Epochs', fontsize=16)\n",
    "plt.ylabel('Mean Absolute error', fontsize=16)\n",
    "plt.xlim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and plotting the future internet activities using LSTM (y_pred_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_LSTM = model_LSTM.predict(X_test)\n",
    "\n",
    "plt.plot(y_test, \"b-+\", label='Ground truth', color = \"red\")\n",
    "plt.plot(y_pred_LSTM, \"-\", label='LSTM prediction', color = \"blue\")\n",
    "plt.legend()\n",
    "plt.xlim(0, 100)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time instannces', fontsize=16)\n",
    "plt.ylabel('Activity', fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
